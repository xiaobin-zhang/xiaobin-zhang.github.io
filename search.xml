<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[reading-protocol-SSL-TLS]]></title>
    <url>%2F2022%2F03%2F30%2Freading-protocol-SSL-TLS%2F</url>
    <content type="text"><![CDATA[本篇主要的内容是: 理解SSL和TLS是什么？作用是什么？它们之间的关系。 最近在阅读阿里的Sentinel的代码，在了解客户端和Dashboard的hearbeat与command时，看到了一段创建Socket的代码，这段代码大意是按照通信协议(HTTP/HTTPS)创建Socket，后续心跳检测和交互通过socket来通信。在创建HTTPS的Socket的代码片段中：SSLContext.getInstance(&quot;TLS&quot;)引起了我的好奇，于时想了解一下TLS到底时什么，在了解TLS的过程中，再次加深了一下HTTPS的对于消息加密的理解。 概述SSL和TLS都属于加密协议，HTTPS为了保证通信的安全对消息的密钥进行了加密。它作于与客户端与服务端进行HTTPS通信的四次握手阶段。TLS可以看作是SSL的升级版本。 主要内容在阅读了阮一峰老师的两篇文章《SSL/TLS协议运行机制的概述》、《图解SSL/TLS协议》之后，生产了以下的笔记内容。 SSL Handshake 握手阶段 SSL(Secure Sockets Layer, 安全套接字协议)与TLS(TransportLayerSecurity, 安全传输层)所解决的问题：防窃听(加密传播)、防篡改(校验机制)、防冒充(身份证书)。 SSL与TLS的历史：SSL是由网景(NetScape)公司1994年设计的，历经3个版本1.0(1994)、2.0(1995)、3.0(1996)。1999年互联网标准化组织(ISOC)接替了网景发布了SSL的升级版TLS 1.0。后续发布了1.1(2006)、1.2(2008)、1.2修正版(2011)。TLS的三个版本也被标注为SSL3.1、SSL3.2、SSL3.3。 SSL和TLS作用与建立连接阶段，客户端首先发起连接请求，通过4次握手生成3个随机数，用3个随机数生成用于加密报文的对话密钥(对称加密报文)。服务器通过公钥仅对对话密钥进行加密，而不对报文进行加密，来减少运算耗时。 客户端首先发起握手请求，并生成第一个随机数(明文可见),服务端回应并生成第二个随机数(明文可见)，客户端收到回执后再次生成第三个随机数(用服务端公钥加密不可见)发给服务端，最后客户端和服务端通过三个随机数生成最终的会话密钥。 为了保证公钥不被篡改，公钥放到了服务端的证书里。只要证书是可信的，公钥就是可信的。 四次握手的过程中客户端与服务端也商定了加密方式，比如RSA公钥加密。 Session恢复握手阶段用来建立SSL连接。如果出于某种原因，对话中断，就需要重新握手。这时有两种方法可以恢复原来的session：一种叫做session ID，另一种叫做session ticket。 Session ID session ID是指客户端给出session ID，服务器确认该编号存在，双方就不再进行握手阶段剩余的步骤，而直接用已有的对话密钥进行加密通信，它的缺点在于session ID往往只保留在一台服务器上。所以，如果客户端的请求发到另一台服务器，就无法恢复对话。 Session Ticket session ticket是指客户端不再发送session ID，而是发送一个服务器在上一次对话中发送过来的session ticket。这个session ticket是加密的，只有服务器才能解密，其中包括本次对话的主要信息，比如对话密钥和加密方法。当服务器收到session ticket以后，解密后就不必重新生成对话密钥了。]]></content>
      <categories>
        <category>学习</category>
        <category>协议</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reading-protocol:amqp0-9-1]]></title>
    <url>%2F2018%2F05%2F07%2Freading-protocol-amqp0-9-1%2F</url>
    <content type="text"><![CDATA[本篇主要的内容是: 解读AMQP协议，协议当前版本是1.0.0，本篇版本的是0.9.1。 概述写本篇的原因是：在平时的工作中，经常会有消息中间件的使用，其中涉及到一种在传统金融领域比较流行的一款消息中间件：RabbitMq。这款消息中间件便基于AMQP开发的。在学习了解过改软件的基本使用后，萌生对其实现的协议–AMQP协议一探究竟的想法。本篇从AMQP官网下载了其0.9.1版本的pdf文档，下面，我将从该文档开始该协议的学习。 主要内容文档前面的引言之类的，本篇就不在累述了。直接从文档第二部分开始。 General Architecture 总体结构AMQ Model ArchitectureMain Entities 我们可以总结一下，一个中间件服务应该是什么样： 它是一个可以接收消息，并且主要完成以下两件事情的数据服务： 根据其依赖的不同的协议，将消息路由到不同的消费者； 当消费者消费能力不足，或者比消费速度比较慢时，它可以将消息缓存到内存或者磁盘。 在预AMQP服务器中，这些任务由实现特定类型路由和缓冲的单块引擎完成。AMQ模型采用较小的模块块的方法，可以以更多样化和更健壮的方式组合起来。AMQ模型首先将这些任务划分为两个不同的角色： Exchange，它负责接收生产者产生的消息，并且路由到消费队列–Message Queue。 Message Queue，它负责保存消息并将消息转发给消费者应用。 在Exchange和Message Queue之间还有一个比较清晰的接口，叫做binding，这个稍后讨论。AMQP提供了运行时可编译语义，只要通过以下两个方面来提现： 具有可以通过该协议创建各种类型的exchange和massage queue的能力； 具有可以通过该协议将exchange和message queue绑定在一起，来创建任何需要的消息处理系统的能力。 The Message Queue消息队列。 AMQP Command ArchitectureAMQP Transport ArchitectureAMQP Client ArchitectureFunctional Specification 功能规格Server Functional SpecificationAMQP Command SpecificationTechnical Specifications 技术规格IANA Assigned Port NumberAMQP Wire-Level FormatChannel MultiplexingVisibility GuaranteeChannel ClosureContent SynchronisationContent Ordering GuranteesError HandlingLimitationsSecurity小结]]></content>
      <categories>
        <category>学习</category>
        <category>协议</category>
      </categories>
      <tags>
        <tag>AMQP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[db2-use-notes]]></title>
    <url>%2F2018%2F04%2F12%2Fdb2-use-notes%2F</url>
    <content type="text"><![CDATA[本篇主要的内容是：在日常工作中，记录DB2的一些操作笔记。 概述在工作当中，会频繁的对数据进行一系列的操作。这里记录了使用DB2数据库比较常见的命令。供以后参考。 主要内容准备工作创建一张临时表，用来举例说明 123456789CREATE TABLE TB_A ( SEQ INTEGER NOT NULL GENERATED BY DEFAULT AS IDENTITY, NAME VARCHAR(20), AGE INTEGER, SALARY DECIMAL(18,2), PRIMARY KEY (SEQ) ); 插入预先准备的演示数据 123456789101112insert into TB_A (NAME,AGE,SALARY) values ('tom',18,3000);insert into TB_A (NAME,AGE,SALARY) values ('bob',18,3000);insert into TB_A (NAME,AGE,SALARY) values ('jck',18,3000);insert into TB_A (NAME,AGE,SALARY) values ('lil',20,3000);insert into TB_A (NAME,AGE,SALARY) values ('mer',20,4000);insert into TB_A (NAME,AGE,SALARY) values ('gor',20,4000);insert into TB_A (NAME,AGE,SALARY) values ('hah',21,2000);insert into TB_A (NAME,AGE,SALARY) values ('yiy',21,4020);insert into TB_A (NAME,AGE,SALARY) values ('sor',21,4010);insert into TB_A (NAME,AGE,SALARY) values ('ppo',21,2000);insert into TB_A (NAME,AGE,SALARY) values ('iio',21,4220);insert into TB_A (NAME,AGE,SALARY) values ('sse',21,4110); 到目前为止，准备工作已经完成：创建了一张临时表，同时插入了演示数据。 数据的导出导入在实际工作当中，经常会使用命令行工具对生产上的数据进行导出，然后对把导出的数据再导入本地临时表中，然后具体分析。 登录数据库1234567/app&gt;db2 connect to DB_NAME user USER_NAME using passwd Database Connection Information Database server = DB2/LINUXX8664 10.1.3 SQL authorization ID = USER_NAME Local database alias = DB_NAME DB_NAME: 数据库名称, USER_NAME: 用户名，passwd : 密码 从表中导出数据到文件在日常工作中，我更喜欢将数据以.ixf文件的格式来导出、导入数据，但必须保证生产上表的结构和字段顺序要和本地临时表保持完全一致，否则会出错。 使用export命令导出数据 12345678910111213141516/app&gt;db2 "export to TB_A.ixf of ixf select * from TB_A";SQL3104N The Export utility is beginning to export data to file "TB_A.ixf".SQL3105N The Export utility has finished exporting "12" rows.Number of rows exported: 12/app&gt;/app&gt;db2 "export to TB_A.csv of del select * from TB_A";SQL3104N The Export utility is beginning to export data to file "TB_A.csv".SQL3105N The Export utility has finished exporting "12" rows.Number of rows exported: 12 从文件导入数据到表使用import命令导入数据 12345678910111213141516171819202122232425262728/app&gt;db2 "import from TB_A.ixf of ixf insert into TB_A";SQL3150N The H record in the PC/IXF file has product "DB2 02.00", date "20180412", and time "142939".SQL3153N The T record in the PC/IXF file has name "TB_A.ixf", qualifier "", and source " ".SQL3109N The utility is beginning to load data from file "TB_A.ixf".SQL3110N The utility has completed processing. "12" rows were read from the input file.SQL3221W ...Begin COMMIT WORK. Input Record Count = "12".SQL3222W ...COMMIT of any database changes was successful.SQL3149N "12" rows were processed from the input file. "12" rows were successfully inserted into the table. "0" rows were rejected.Number of rows read = 12Number of rows skipped = 0Number of rows inserted = 12Number of rows updated = 0Number of rows rejected = 0Number of rows committed = 12/app&gt; 分组小计在日常工作中，偶尔会有这种需求：对分组后的结果集取每组前n条信息，在之前学习的oracle数据库中，有伪劣的概念，在DB2中，也有办法来实现。下面以几个小例子来展示。 使用row_number() over(…)来对分组后结果集进行再次处理。 123select age,name,salary,row_number() over(order by age asc) as age_rn from tb_a group by age,name,salary order by age; 123select age,name,salary,row_number() over(partition by age order by age asc) as age_rn from tb_a group by age,name,salary order by age; 来对比一下这两条SQL的执行结果 首先这两条都语句的目的，都是对分组查询后的结果集的二次操作。区别在于第二条在over括号内使用了partition by，从两条结果集的对比中，发现，partiton by 的作用是，对结果集中，某一列再次分组，如果没有partiton by,则把结果集看做一个整体。 按照上面的分析。现在就可以做到下面这种业务场景的要求了 对TB_A按照年龄分组，取出每组的前两条信息 123456SELECT * FROM ( select age,name,salary,row_number() over(partition by age order by age asc) as age_rn from tb_a group by age,name,salary order by age ) WHERE age_rn &lt;= 2 小结在本篇中，纪录了日常工作中较为常用的几个DB2命令。希望在工作中可以起到一点帮助作用。]]></content>
      <categories>
        <category>笔记</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>DB2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-learning-getStarted]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-learning-getStarted%2F</url>
    <content type="text"><![CDATA[本篇的主要内容是：介绍Docker使用的基础知识。 概述在上一章节中，已经安装好了Docker，在本篇中就要开始学习Docker的基本操作了。在本篇分为以下6部分来学习。 Orientation Containers Services Swarms Stacks Deploy your app 主要内容Orientation官方链接：https://docs.docker.com/get-started/ Docker是为开发人员或系统管理员提供的，可以开发，部署，运行应用程序的容器平台。这种在linux下使用容器来部署应用的方式，被称作集装箱化，意思就是把应用当做货轮上的一个一个的集装箱，而linux就相当于货轮。容器技术不是新出现的技术，但是它的确是一种便于部署应用的一个很好的方式。 NOTE ： Containerization被翻译为集装箱化，听起来太难听了。接下来的文章中，我就直接叫它容器化了。 容器化之所以越来越受欢迎的原因是，采用这种方式有以下几个优点： 灵活性：任何甚至最复杂的应用都可以采用该方案 轻量级：容器充分利用和共享主机内核 可替换：可以在应用运行过程中，部署和升级 可移植：可以在本地构建，然后上传部署到云上，之后可以随处运行 伸缩性：可以增加和自动分发容器副本 堆栈：在运行中可以垂直堆叠服务 Images and containers镜像和容器。通过运行一个镜像来启动一个容器。一个镜像就是一个可运行的包，这个package包括了这个应用可运行的一切要素，例如应用源码、环境变量、运行时间、依赖、配置文件等。一个容器就是内存中，被启动的镜像的一个运行时实例。可以用docker ps 来查看当前系统中正在运行中的容器 Containers and virtual machines容器和虚拟机。在本地linux下运行的一个容器和其他的容器共享主机内核,它是不会长期的占用系统资源，比其他可执行的应用占用更小的内存，更轻量级。 在虚拟机下，相比于使用访客用户来独立部署应用，Docker使用容器方式部署应用要占用更少的系统资源。 简单命令查看当前系统安装的Docker版本1234567891011121314151617181920212223[root@VM_0_3_centos ~]# docker -vDocker version 18.03.0-ce, build 0520e24[root@VM_0_3_centos ~]# docker versionClient: Version: 18.03.0-ce API version: 1.37 Go version: go1.9.4 Git commit: 0520e24 Built: Wed Mar 21 23:09:15 2018 OS/Arch: linux/amd64 Experimental: false Orchestrator: swarmServer: Engine: Version: 18.03.0-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.4 Git commit: 0520e24 Built: Wed Mar 21 23:13:03 2018 OS/Arch: linux/amd64 Experimental: false[root@VM_0_3_centos ~]# 查看当前系统下的镜像1234[root@VM_0_3_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest f2a91732366c 4 months ago 1.85kB[root@VM_0_3_centos ~]# 查看当前系统下正在运行容器123[root@VM_0_3_centos ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@VM_0_3_centos ~]# 查看当前系统下全部的容器1234[root@VM_0_3_centos ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7570316825e8 hello-world "/hello" 19 hours ago Exited (0) 19 hours ago relaxed_pasteur[root@VM_0_3_centos ~]# Conclusion orientation容器化可以使应用做到无缝的持续集成、持续部署,例如： 应用间没有依赖 可以将应用更新推送到任意其他的分支应用 可以优化资源配比 使用Docker，要做到可弹性化的应用只需要一个配置文件即可，而不需要再运行笨重的虚拟机。 Containers官方链接：https://docs.docker.com/get-started/ 在以前，如果我们需要开始写一个Python App时，首先需要做的，是在自己的机器上，搭建Python的运行环境，这样就需要我们必须安装正确合理的运行环境，并且要和生成还款一致。现在，使用Docker，只需要获取一个便捷的Python运行时的镜像即可，不需要安装。然后,再添加一些运行必要的依赖即可，这些都可以在进行中完成。这些便捷的镜像，是通过Dockerfile来定义的。 Define a container with Dockerfile使用Dockerfile来定义一个容器。Dockerfile定义了容器内的环境。在这种环境中，对网络接口和磁盘驱动器等资源的访问都是虚拟化的，这与系统其他部分是隔离的。需要自己映射到容器外部的端口，可以指定需要copy到容器的文件。不管怎样，当你定义完成之后，这个你构建的容器，无论在哪里运行，它的运行结果和行为都完全和你预期的一致。 创建一个空目录，cd到该目录下，touch一个名为Dockerfile文件,复制下面的内容到Dockerfile文件中，注意要文件中，语句的注释。1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] 上面Dockerfile提到的文件app.py和requirements.txt还没有建立，接下来，先来创建它们 The app itself在Dockerfile文件的同级目录下再创建两个文件，requirements.txt和app.py，这样我们这个简单的app就完成了。 requirements.txt12FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) 构建Docker镜像 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@VM_0_3_centos dkt]# docker build -t friendlyhello .Sending build context to Docker daemon 4.608kBStep 1/7 : FROM python:2.7-slim2.7-slim: Pulling from library/pythonb0568b191983: Pull complete 55a7da9473ae: Pull complete 422d2e7f1272: Pull complete 8fb86f1cff1c: Pull complete Digest: sha256:9e24a026a55ca1d9a7284db30ed846b7190a3d7f557edf493b454bff362ed64cStatus: Downloaded newer image for python:2.7-slim ---&gt; b16fde09c92cStep 2/7 : WORKDIR /appRemoving intermediate container a2c0422a46fa ---&gt; b3f84ed88338Step 3/7 : ADD . /app ---&gt; 74a6295086c5Step 4/7 : RUN pip install --trusted-host pypi.python.org -r requirements.txt ---&gt; Running in d3b6fc400e6dCollecting Flask (from -r requirements.txt (line 1)) Downloading Flask-0.12.2-py2.py3-none-any.whl (83kB)Collecting Redis (from -r requirements.txt (line 2)) Downloading redis-2.10.6-py2.py3-none-any.whl (64kB)Collecting itsdangerous&gt;=0.21 (from Flask-&gt;-r requirements.txt (line 1)) Downloading itsdangerous-0.24.tar.gz (46kB)Collecting Jinja2&gt;=2.4 (from Flask-&gt;-r requirements.txt (line 1)) Downloading Jinja2-2.10-py2.py3-none-any.whl (126kB)Collecting Werkzeug&gt;=0.7 (from Flask-&gt;-r requirements.txt (line 1)) Downloading Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)Collecting click&gt;=2.0 (from Flask-&gt;-r requirements.txt (line 1)) Downloading click-6.7-py2.py3-none-any.whl (71kB)Collecting MarkupSafe&gt;=0.23 (from Jinja2&gt;=2.4-&gt;Flask-&gt;-r requirements.txt (line 1)) Downloading MarkupSafe-1.0.tar.gzBuilding wheels for collected packages: itsdangerous, MarkupSafe Running setup.py bdist_wheel for itsdangerous: started Running setup.py bdist_wheel for itsdangerous: finished with status 'done' Stored in directory: /root/.cache/pip/wheels/fc/a8/66/24d655233c757e178d45dea2de22a04c6d92766abfb741129a Running setup.py bdist_wheel for MarkupSafe: started Running setup.py bdist_wheel for MarkupSafe: finished with status 'done' Stored in directory: /root/.cache/pip/wheels/88/a7/30/e39a54a87bcbe25308fa3ca64e8ddc75d9b3e5afa21ee32d57Successfully built itsdangerous MarkupSafeInstalling collected packages: itsdangerous, MarkupSafe, Jinja2, Werkzeug, click, Flask, RedisSuccessfully installed Flask-0.12.2 Jinja2-2.10 MarkupSafe-1.0 Redis-2.10.6 Werkzeug-0.14.1 click-6.7 itsdangerous-0.24Removing intermediate container d3b6fc400e6d ---&gt; 4df35974b59fStep 5/7 : EXPOSE 80 ---&gt; Running in d22d83548539Removing intermediate container d22d83548539 ---&gt; 7e7c88118497Step 6/7 : ENV NAME World ---&gt; Running in 5a9c2cfde214Removing intermediate container 5a9c2cfde214 ---&gt; 462234d15e1aStep 7/7 : CMD ["python", "app.py"] ---&gt; Running in 26ce9fb35867Removing intermediate container 26ce9fb35867 ---&gt; 551973057533Successfully built 551973057533Successfully tagged friendlyhello:latest[root@VM_0_3_centos dkt]# 查看当前镜像 1234[root@VM_0_3_centos dkt]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest 551973057533 6 minutes ago 150MBpython 2.7-slim b16fde09c92c 2 weeks ago 139MB 这里和官网不同的是，使用build命令构建之后，会生成两个镜像。进过测试发现，在Dockerfile中配置几个FROM … ,构建后就会创建FROM 后面指定的镜像。 Run app1234567[root@VM_0_3_centos dkt]# docker run -p 3000:80 friendlyhello * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)[root@VM_0_3_centos ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES975aedd8d085 friendlyhello &quot;python app.py&quot; 35 seconds ago Up 35 seconds 0.0.0.0:3000-&gt;80/tcp focused_villani[root@VM_0_3_centos ~]# 使用 run 命令启动一个镜像，可以使用 -p 命令指定容器外部的端口和内部端口的映射，上面命令指定外部端口为3000映射容器内部的80端口。 123456[root@VM_0_3_centos dkt]# docker run -d --name my-first-app friendlyhello7417b8f4d62e05a2ba32dde6f9ae64b3bd5e6ae4c411cca405f3730e3f4e8be5[root@VM_0_3_centos dkt]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7417b8f4d62e friendlyhello "python app.py" 3 seconds ago Up 2 seconds 80/tcp my-first-app[root@VM_0_3_centos dkt]# 使用 -d 参数让容器在后台运行，使用 –name 参数后面加自定义的名字，可以为启动的容器命名。 123[root@VM_0_3_centos dkt]# docker logs my-first-app * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)[root@VM_0_3_centos dkt]# 使用 docker logs 后面加容器名，可以打印出容器的日志信息。 Share your image分享镜像。如果是首次登陆的话，需要到官网去注册一个账户。 Login123456[root@VM_0_3_centos dkt2]# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: xiaobinzhangPassword: Login Succeeded[root@VM_0_3_centos dkt2]# Tag the image本地机器上的镜像和远程服务器上的镜像之间的映射关系是：username/repository:tag。tag是可选的，但是强烈建议为每个版本的镜像打一个不同的版本标签。 123456789[root@VM_0_3_centos ~]# docker tag --helpUsage: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]Create a tag TARGET_IMAGE that refers to SOURCE_IMAGEOptions:[root@VM_0_3_centos ~]# 下面就使用tag创建一个镜像，并给该进行指定版本 123456789101112131415[root@VM_0_3_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest 551973057533 22 hours ago 150MBcentos latest e934aafc2206 4 days ago 199MBredis latest c5355f8853e4 2 weeks ago 107MBpython 2.7-slim b16fde09c92c 2 weeks ago 139MB[root@VM_0_3_centos ~]# docker tag redis:latest xiaobinzhang/redis:0.0.1[root@VM_0_3_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest 551973057533 22 hours ago 150MBcentos latest e934aafc2206 4 days ago 199MBredis latest c5355f8853e4 2 weeks ago 107MBxiaobinzhang/redis 0.0.1 c5355f8853e4 2 weeks ago 107MBpython 2.7-slim b16fde09c92c 2 weeks ago 139MB[root@VM_0_3_centos ~]# 上面基于本地当前的redis镜像，重新制作了一个tag为0.0.1,镜像名为xiaobinzhang/redis的镜像。 NOTE :官方文档上的命令是 docker tag image username/repository:tag 但是，我自己在本机操作后，发现这样不可。12345678[root@VM_0_3_centos ~]# docker tag image centos xiaobinzhang/centos:0.0.1"docker tag" requires exactly 2 arguments.See 'docker tag --help'.Usage: docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE[root@VM_0_3_centos ~]# Publish the image推送镜像。上传刚刚标记过的镜像到自己的仓库。 123456789[root@VM_0_3_centos ~]# docker push xiaobinzhang/redis:0.0.1The push refers to repository [docker.io/xiaobinzhang/redis]dc532c93e196: Mounted from library/redis 4809734bf3c3: Mounted from library/redis e7c4433350f1: Mounted from library/redis b92d098685e5: Mounted from library/redis 27af3b14aa14: Mounted from library/redis 43efe85a991c: Mounted from library/redis 0.0.1: digest: sha256:1415c3ce635e1bb7e9d672c476f70fa9ddbe720f01d419babcdd2235103f7a85 size: 1571 上传成功后，登录https://hub.docker.com 到自己的账户下，可以看到刚刚上传成功的镜像。如果你设置的自己的仓库为公共的，那么，你上传的进项，可以被所有人使用。 Pull and run the image from the remote repository从远程仓库下载镜像。 首先删除本地镜像，使用 rmi 删除镜像，使用 rm 删除容器。 1[root@VM_0_3_centos ~]# docker rmi xiaobinzhang/redis:0.0.1 然后下载运行远程的镜像 1234[root@VM_0_3_centos ~]# docker run xiaobinzhang/redis:0.0.1Unable to find image 'xiaobinzhang/redis:0.0.1' locallydocker: Error response from daemon: pull access denied for xiaobinzhang/redis, repository does not exist or may require 'docker login'.See 'docker run --help'. 出现上面这种情况的原因是，我把刚上传的这个仓库设置成为了private的，所以下载失败。登入hub.docker手动置为public，再次执行。 1234567891011121314151617181920[root@VM_0_3_centos ~]# docker run xiaobinzhang/redis:0.0.1Unable to find image 'xiaobinzhang/redis:0.0.1' locally0.0.1: Pulling from xiaobinzhang/redisDigest: sha256:1415c3ce635e1bb7e9d672c476f70fa9ddbe720f01d419babcdd2235103f7a85Status: Downloaded newer image for xiaobinzhang/redis:0.0.11:C 11 Apr 08:10:48.377 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo1:C 11 Apr 08:10:48.377 # Redis version=4.0.9, bits=64, commit=00000000, modified=0, pid=1, just started1:C 11 Apr 08:10:48.377 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf1:M 11 Apr 08:10:48.379 * Running mode=standalone, port=6379.1:M 11 Apr 08:10:48.379 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.1:M 11 Apr 08:10:48.379 # Server initialized1:M 11 Apr 08:10:48.379 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.1:M 11 Apr 08:10:48.379 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.1:M 11 Apr 08:10:48.379 * Ready to accept connections^C1:signal-handler (1523434363) Received SIGINT scheduling shutdown...1:M 11 Apr 08:12:43.744 # User requested shutdown...1:M 11 Apr 08:12:43.744 * Saving the final RDB snapshot before exiting.1:M 11 Apr 08:12:43.753 * DB saved on disk1:M 11 Apr 08:12:43.754 # Redis is now ready to exit, bye bye...[root@VM_0_3_centos ~]# 执行成功，其实可以使用 docker pull xiaobinzhang/redis:0.0.1 的方式，拉去远程仓库的镜像。只要将应用，包括该应用运行时需要的一切依赖、环境、源码等等制作为一个镜像，那么无论在什么地方，只要docker可以启动，并且能够拉去你上传的镜像，这个镜像不需要其他的配置和安装，就可以运行起来。 Conclusion containers到现在为止，已经掌握了docker的基本操作命令。在简单的使用中，已经完全足够了。 查看镜像列表 查看运行时容器 查看全部容器 运行容器，并指定后台运行，指定容器别名，映射端口 删除容器，删除镜像 Dockerfile的组成和关键字 从Dockerfile构建一个镜像 为镜像打版本标签 推送本地镜像到远程仓库 从远程仓库拉取镜像到本地 接下来将要学习，如何通过在服务中运行容器来扩展我们的引用。 Services官方链接：https://docs.docker.com/get-started/part3/ 在分布式应用中，我们把不同的模块称之为服务。在Docker中，我们可以把一个容器称之为一个服务。那么问题就来了，既然是服务，我们就要考虑一个服务需要满足的一些要求，比如它对外暴露的端口，编码，以及负载均衡，等等。幸运的是，在docker中定义这些是非常的容易的。在Docker平台，定义、运行、弹性扩展等操作，只需要编辑 docker-compose.yml文件即可。 docker-compose.ymltouch一个名为docker-compose.yml的文件，复制以下信息到文件中。 12345678910111213141516171819version: &quot;3&quot;services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 resources: limits: cpus: &quot;0.1&quot; memory: 50M restart_policy: condition: on-failure ports: - &quot;80:80&quot; networks: - webnetnetworks: webnet: 这个docker-compose.yml文件告诉Docker需要完成以下几件事情 从远程仓库拉去镜像 启动5个镜像的实例，限制每个实例最多使用10%的CPU和50M的内存 当着6个实例只要有一个失败时立即重启一个代替 映射端口80:80 从服务80端口对服务内部实例做负载均衡 设置默认的负载均衡网络 NOTE ：yml文件的缩进格式不要写错，否则会在执行下面指令的时候，会报错。 Run your new load-balanced app运行一个新的负载均衡应用。 首先执行下面这条命令 1[root@VM_0_3_centos dkt2]# docker swarm init NOTE : 在稍后的章节在解释docker swarm init这个命令的含义。但是此时如果不先执行这条语句的话，会抛一个错误“this node is not a swarm manager”。 现在，来运行这个应用，此时我们只有一个docker-compose.yml文件，并且执行了一个docker swarm init命令。下面我们在给这个应用起一个名字：getstartedlab。 123[root@VM_0_3_centos dkt3]# docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web 执行完成后，如果我们的这个镜像是被部署在一台主机上的话，那么此时这个一个单独的服务栈运行了5个容器实例。接下来我们来验证一下。 123[root@VM_0_3_centos dkt3]# docker service lsID NAME MODE REPLICAS IMAGE PORTSdlo3u47w91el getstartedlab_web replicated 5/5 xiaobinzhang/friendlyhello:0.0.1 *:80-&gt;80/tcp 现在可以看到，机器中有一个以刚刚我们给命名为前缀的web服务:getstartedlab_web,并且可以看到这个服务的ID、复制的数量、镜像名和对外的端口。 一个单独运行的容器实例被称为task。每一个task都有一个唯一的ID，按照docker-compose.yml文件中配置的replicas个数，而启动几个task。用下面命令来列出这个服务的全部task列表。 12345678[root@VM_0_3_centos dkt2]# docker service ps getstartedlab_web ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSeevy540v8ni6 getstartedlab_web.1 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 21 minutes ago 29k0z7sjhams getstartedlab_web.2 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 21 minutes ago 2h7ttm705fll getstartedlab_web.3 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 21 minutes ago pszqwmkjffdp getstartedlab_web.4 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 21 minutes ago swiw8plaoof0 getstartedlab_web.5 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 21 minutes ago [root@VM_0_3_centos dkt2]# 现在执行以下curl -4 http://localhost来看一下负载均衡的效果。 1234567891011[root@VM_0_3_centos ~]# curl -4 http://localhost&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 54ef1e81d62d&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;[root@VM_0_3_centos ~]# [root@VM_0_3_centos ~]# curl -4 http://localhost&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 04b047c14f53&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;[root@VM_0_3_centos ~]# [root@VM_0_3_centos ~]# curl -4 http://localhost&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; abb6fb33581b&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;[root@VM_0_3_centos ~]# [root@VM_0_3_centos ~]# curl -4 http://localhost&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 446c7e5fcff2&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;[root@VM_0_3_centos ~]# [root@VM_0_3_centos ~]# curl -4 http://localhost&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 09591611aae3&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;[root@VM_0_3_centos ~]# [root@VM_0_3_centos ~]# 123456[root@VM_0_3_centos ~]# docker container ls -qabb6fb33581b54ef1e81d62d446c7e5fcff204b047c14f5309591611aae3 可以看到，每次访问结果返回的Hostname都不一样，并且Hostname都在这个web服务的ID列表中。 Scale the app弹性扩展应用。可以通过修改docker-compose.yml文件中replicas的值来对该服务进行弹性扩容。修改之后，运行docker stack deploy命令即可生效。 现在修改replicas的值由5改为4。并且重新部署。 12[root@VM_0_3_centos dkt3]# docker stack deploy -c docker-compose.yml getstartedlabUpdating service getstartedlab_web (id: dlo3u47w91el1r259c2tt2fp1) 几秒钟后，检查一下 12345678910[root@VM_0_3_centos ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSdlo3u47w91el getstartedlab_web replicated 4/4 xiaobinzhang/friendlyhello:0.0.1 *:80-&gt;80/tcp[root@VM_0_3_centos ~]# docker service ps getstartedlab_web ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSeevy540v8ni6 getstartedlab_web.1 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 34 minutes ago 29k0z7sjhams getstartedlab_web.2 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 34 minutes ago 2h7ttm705fll getstartedlab_web.3 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 34 minutes ago pszqwmkjffdp getstartedlab_web.4 xiaobinzhang/friendlyhello:0.0.1 VM_0_3_centos Running Running 34 minutes ago [root@VM_0_3_centos ~]# 现在可以看到，机器中的service的REPLICAS信息已经发生了变化。并且运行中的容器实例也由之前的5个变为了4个。Docker平台可以就地更新，不需要杀死一些进程或容器。 Take down the app and the swarm卸载应用集群。 使用docker stack rm卸载应用 123[root@VM_0_3_centos dkt3]# docker stack rm getstartedlab Removing service getstartedlab_webRemoving network getstartedlab_webnet 12[root@VM_0_3_centos ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTS 现在已近卸载了getstartedlab应用 再卸载swarm，swarm内容在今后的章节中介绍。 12[root@VM_0_3_centos dkt3]# docker swarm leave --forceNode left the swarm. Conclusion services到目前为止，已近掌握了服务的概念，通过services的学习，掌握了以下结果知识点： docker-compose.yml的配置 通过修改配置文件达到服务的弹性扩展 从docker-compose.yml启动服务的步骤 Docker平台就地更新的特性 服务的卸载和swarm的卸载 现在已近在容器学习中迈出了巨大的一步，在接下来，将学习在一个Docker集群中，怎样把我们的应用以真正的集群的方式运行。 Swarms集群。接下来将继续学习在集群上部署我们的应用，在多台机器上运行。 Stacks栈。 Deploy your app部署应用。 总结总结。]]></content>
      <categories>
        <category>学习</category>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-learning-getDocker]]></title>
    <url>%2F2018%2F04%2F09%2Fdocker-learning-getDocker%2F</url>
    <content type="text"><![CDATA[本篇主要的内容是：在linux操作系统下，下载安装Docker。 概述在CentOS操作系统下，安装Docker。Docker有两个版本，一个是社区版本CE，一个是企业版本EE。本次安装的是社区版本。有两种方式来安装Docker，一种是使用YUM repository，一种是使用RPM package。本次使用YUM reppository来安装。 Note：强烈建议使用YUM repository方式来安装Docker，这样便于对Docker的更新和管理。如果是在没有网络连接的环境中，就只能使用RPM package方式手动安装了。 操作步骤检查系统信息1234567[root@VM_0_3_centos ~]# lsb_release -aLSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.2.1511 (Core) Release: 7.2.1511Codename: Core[root@VM_0_3_centos ~]# 卸载旧版本123456789101112131415161718[root@VM_0_3_centos ~]# sudo yum remove dockerLoaded plugins: fastestmirror, langpacksRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fastNo Match for argument: dockerNo Packages marked for removal[root@VM_0_3_centos ~]# sudo yum remove docker-client\&gt; docker-client-latest\&gt; docker-common\&gt; docker-latest\&gt; docker-latest-logrotate\&gt; docker-selinux\&gt; docker-engine-selinux\&gt; docker-engineLoaded plugins: fastestmirror, langpacksRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fastNo Match for argument: docker-clientdocker-client-latestdocker-commondocker-latestdocker-latest-logrotatedocker-selinuxdocker-engine-selinuxdocker-engineNo Packages marked for removal[root@VM_0_3_centos ~]# 之前没有安装过，所以卸载旧版本这步可以忽略。 安装必要的包123[root@VM_0_3_centos ~]# sudo yum install -y yum-utils \&gt; device-mapper-persistent-data \&gt; lvm2 当输出以下信息，则说明安装成功 123456789101112Updated: device-mapper-persistent-data.x86_64 0:0.7.0-0.1.rc6.el7_4.1 lvm2.x86_64 7:2.02.171-8.el7 yum-utils.noarch 0:1.1.31-42.el7 Dependency Updated: device-mapper.x86_64 7:1.02.140-8.el7 device-mapper-event.x86_64 7:1.02.140-8.el7 device-mapper-event-libs.x86_64 7:1.02.140-8.el7 device-mapper-libs.x86_64 7:1.02.140-8.el7 lvm2-libs.x86_64 7:2.02.171-8.el7 python-urlgrabber.noarch 0:3.10-8.el7 rpm.x86_64 0:4.11.3-25.el7 rpm-build-libs.x86_64 0:4.11.3-25.el7 rpm-libs.x86_64 0:4.11.3-25.el7 rpm-python.x86_64 0:4.11.3-25.el7 yum.noarch 0:3.4.3-154.el7.centos.1 Complete! 配置仓库1234567[root@VM_0_3_centos ~]# sudo yum-config-manager \&gt; --add-repo \&gt; https://download.docker.com/linux/centos/docker-ce.repoLoaded plugins: fastestmirror, langpacksadding repo from: https://download.docker.com/linux/centos/docker-ce.repograbbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.reporepo saved to /etc/yum.repos.d/docker-ce.repo 安装Docker1[root@VM_0_3_centos ~]# sudo yum install docker-ce 安装期间会有两次提示，第一次提示是告知下载内容大小，询问是否下载，第二次是提示GPG密钥验证，这两次提示都选则yes。当输出以下信息，标识安装成功 12345678910111213Installed: docker-ce.x86_64 0:18.03.0.ce-1.el7.centos Dependency Installed: audit-libs-python.x86_64 0:2.7.6-3.el7 checkpolicy.x86_64 0:2.5-4.el7 container-selinux.noarch 2:2.42-1.gitad8f0f7.el7 libcgroup.x86_64 0:0.41-13.el7 libseccomp.x86_64 0:2.3.1-3.el7 libsemanage-python.x86_64 0:2.5-8.el7 pigz.x86_64 0:2.3.4-1.el7 policycoreutils-python.x86_64 0:2.5-17.1.el7 python-IPy.noarch 0:0.75-6.el7 setools-libs.x86_64 0:3.3.8-1.1.el7 Dependency Updated: audit.x86_64 0:2.7.6-3.el7 audit-libs.x86_64 0:2.7.6-3.el7 libsemanage.x86_64 0:2.5-8.el7 policycoreutils.x86_64 0:2.5-17.1.el7 Complete! 此时Docker已经安装了，但是还未启动，并且会建立一个用户组:docker，但是没有这个组里现在没有任何用户，可以使用以下命令查看 123[root@VM_0_3_centos ~]# cat /etc/group | grep dockerdocker:x:988:[root@VM_0_3_centos ~]# 可以查看Docker版本 123[root@VM_0_3_centos ~]# docker -vDocker version 18.03.0-ce, build 0520e24[root@VM_0_3_centos ~]# 启动Docker 12[root@VM_0_3_centos ~]# sudo systemctl start docker[root@VM_0_3_centos ~]# 验证Docker是否安装正确，下面这条命令会下载一个hello-world的镜像，并且启动它,它会打印出信息，然后退出。 1234567891011121314151617181920212223242526272829[root@VM_0_3_centos ~]# sudo docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-worldca4f61b1923c: Pull complete Digest: sha256:97ce6fa4b6cdc0790cda65fe7290b74cfebd9fa0c9b8c38e979330d547d22ce1Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the "hello-world" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/For more examples and ideas, visit: https://docs.docker.com/engine/userguide/[root@VM_0_3_centos ~]# 小结本篇主要的内容就是介绍在有网络CentOS环境下Docker CE的下载和安装，下载前要检查自己系统的版本必须在CentOS 7。如果之前安装过Docker，则需要先删除系统中存在的旧版本。安装过程主要分为三部分，第一部分是依赖包的下载和安装，第二部分是配置Docker仓库，第三部分就是Docker的下载和安装，非常简单。最后我们测试了一下是否正确安装成功。强烈建议的是如果在有网络的环境下，尽量采用本篇的方式来安装，这样对以后版本的升级和管理都非常方便，那实在是没有网络的话，就只能采用RPM包手动安装了。本篇已经成功安装了Docker CE，在接下来的章节中，将要介绍Docker使用的基础知识。]]></content>
      <categories>
        <category>学习</category>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
